{"blog_id": "fernandog16", "summary": ["This paper describes how rank pooling, a very recent approach for pooling representations organized in a sequence $\\\\{{\\bf v}_t\\\\}_{t=1}^T$, can be used in an end-to-end trained neural network architecture.", "Rank pooling is an alternative to average and max pooling for sequences, but with the distinctive advantage of maintaining some order information from the sequence.", "Rank pooling first solves a regularized (linear) support vector regression (SVR) problem where the inputs are the vector representations ${\\bf v}_t$ in the sequence and the target is the corresponding index $t$ of that representation in the sequence (see Equation 5).", "The output of rank pooling is then simply the linear regression parameters $\\bf{u}$ learned for that sequence.", "Because of the way ${\\bf u}$ is trained, we can see that ${\\bf u}$ will capture order information, as successful training would imply that ${\\bf u}^\\top {\\bf v}_t <\u00a0{\\bf u}^\\top {\\bf v}_{t'} $ if $t < t'$.", "See [this paper]( [url]"], "author_id": "hlarochelle", "pdf_url": "http://proceedings.mlr.press/v48/fernando16.pdf", "author_full_name": "Hugo Larochelle", "source_website": "https://www.shortscience.org/user?name=hlarochelle", "id": 41467472}