{"blog_id": "1811.12889", "summary": ["The paper discusses neural module network trees (NMN-trees).", "Here modules are composed in a tree structure to answer a question/task and modules are trained in different configurations to ensure they learn more core concepts and can generalize.", "Longer summary:  How to perform systematic generalization?", "First we need to ask how good current models are at understanding language.", "Adversarial examples show how fragile these models can be.", "This leads us to conclude that systematic generalization is an issue that requires specific attention.", "Maybe we should rethink the modeling assumptions being made.", "We can think that samples can come from different data domains but are generated by some set of shared rules.", "If we correctly learned these rules then domain shift in the test data would not hurt model performance.", "Currently we can construct an experiment to introduce systematic bias in the data which causes the performance to suffer.", "From this experiment we can start to determine what the issue is.", "A recent new idea is to force a model to have more independent units is neural module network trees (NMN-trees).", "Here modules are composed in a tree structure to answer a question/task and modules are trained in different configurations to ensure they learn more core concepts and can generalize."], "author_id": "joecohen", "pdf_url": "http://arxiv.org/pdf/1811.12889v3", "author_full_name": "Joseph Cohen", "source_website": "https://www.shortscience.org/user?name=joecohen", "id": 6799048}