{"blog_id": "lingghkswb16", "summary": ["This paper presents a conditional generative model of text, where text can be generated either one character at a time or by copying some full chunks of character taken directly from the input into the output.", "At each step of the generation, the model can decide which of these two modes of generation to use, mixing them as needed to generate a correct output.", "They refer to this structure for generation as Latent Predictor Networks  [ref] .", "The character-level generation part of the model is based on a simple output softmax over characters, while the generation-by-copy component is based on a Pointer Network architecture.", "Critically, the authors highlight that it is possible to marginalize over the use of either types of components by dynamic programming as used in semi-Markov models  [ref] .", "One motivating application is machine translation, where the input might contain some named entities that should just be directly copied at the output.", "However, the authors experiment on a different problem, that of generating code that would implement the action of a card in the trading card games Magic the Gathering and Hearthstone.", "In this application, copying is useful to do things such as copy the name of the card or its numerically-valued effects.", "In addition to the Latent Predictor Network structure, the proposed model for this application includes a slightly adapted form of soft-attention as well as character-aware word embeddings as in  [ref]  Also, the authors experiment with a compression procedure on the target programs, that can help in reducing the size of the output space.", "Experiments show that the proposed neural network approach outperforms a variety of strong baselines (including systems based on machine translation or information retrieval)."], "author_id": "hlarochelle", "pdf_url": "http://arxiv.org/pdf/1603.06744", "author_full_name": "Hugo Larochelle", "source_website": "https://www.shortscience.org/user?name=hlarochelle", "id": 21532550}