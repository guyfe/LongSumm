{"blog_id": "hardnet", "summary": ["What:  HardNet model which improves state-of-the-art in wide baseline stereo, patch matching, verification and image retrieval.", "They introduced a new triplet-like loss function with built-in hard-negative mining.", "How:  HardNet Triplet loss is a regular Triplet-Loss, i.e. MAX(0, alpha + distances_to_positives - distances_to_negatives), where:  alpha (sometimes called \"margin\") is a hyper-parameter  distance_to_positives are distances (here, L2 is used)  distance_to_negative are distances to the hardest negatives for each anchor in a batch.", "As input HardNet operates with N * 2 images (N anchor/query images and N corresponding to them positives)  Mining algorithm: 1.", "Compute distance matrix D between N anchors and N positives.", "2. distances_to_positives = trace of distance matrix (diagonal elements) 3.", "For each row minimal non-diagonal element is taken as a distance to the hardest negatives (closest to anchor).", "From these chosen values distances_to_negatives are obtained.", "All this can be rewritten as:  Loss = MAX(0, alpha + Trace(D) + row_wise_min(D + I * inf)), where I is the identity matrix.", "Architecture:  Notes:  The described mining procedure highly relies on a fact that all N anchors would should to N different classes.", "And from my personal point of view requires minor modification to handle such corner case.", "The given loss/mining procedure is fast, but in contrast to other mining strategies doesn't provide hardest positive (furthest from anchor).", "Results:  Wide baseline stereo example:  The bigger batch size, the better:  PhotoTour Patch Verification Results:  Oxford 5k, Paris 6k Patch Verification Results:"], "author_id": "ALEJU", "pdf_url": "https://arxiv.org/pdf/1705.10872", "author_full_name": "Alexander Jung", "source_website": "https://github.com/aleju/papers", "id": 69119323}