{"blog_id": "challenging-common-assumptions-in-the-unsupervised-learning-of-disentangled-representations", "summary": ["Challenging common assumptions in the unsupervised learning of disentangled representations Locatello et al., ICML\u201919  Today\u2019s paper choice won a best paper award at ICML\u201919.", "The \u2018common assumptions\u2019 that the paper challenges seem to be: \u201cunsupervised learning of disentangled representations is possible, and useful!\u201d  The key idea behind the unsupervised learning of disentangled representations is that real-world data is generated by a few explanatory factors of variation which can be recovered by unsupervised learning algorithms.", "In this paper, we provide a sober look at recent progress in the field and challenge some common assumptions.", "What exactly is a \u2018disentangled representation\u2019 and why might we want one?", "Put the \u2018disentangled\u2019 part to one side for a moment, and let\u2019s start out by revisiting what we mean by a representation.", "Given a real-world observation  (e.g. of an image or video), a representation  is a transformation of  (typically to a lower dimensional space in order to be useful) that somehow preserves the salient information in the  so that we can still use  to extract useful information about the input (e.g.", "for building classifiers).", "As a trivial example, suppose we had real world observations consisting of 1000 points sampled from a straight line, a good lower-valued representation would be a (gradient, intercept) tuple.", "Of course real-world examples are much more complex than this!", "A disentangled representation is a representation with a compact and interpretable structure, which captures the essence of the input independent of the task the representation is ultimately going to be used for.", "That\u2019s quite tricky \u2013 even in my contrived straight line example what looked to be a great representation would be useless if the task turned out to be calculating the area of the the rectangle enclosed by the points in the observation.", "While there is no single formalized notion of disentanglement (yet) which is widely accepted, the key intuition is that a disentangled representation should separate the distinct information factors of variation in the data.", "A change in a single underlying factor of variation should lead to a change in a single factor in the learned representation.", "The state of the art for representation learning centres around Variational Autoencoders, using one deep neural network to learn a representation, and another one to attempt to reconstruct the original input from that representation.", "The representation  is usually taken as the mean of the approximate posterior distribution of the first (encoding) network.", "In theory, disentanglement is impossible  We theoretically prove that (perhaps unsurprisingly) the unsupervised learning of disentangled representations is fundamentally impossible without inductive biases both on the considered learning approaches and the data sets.", "The full proof is giving in appendix A (missing from my copy of the pdf), but it boils down to this:  My layman\u2019s interpretation is this: given all the possible ways we could   decompose the input into factors, whatever representation we ultimately choose there is some other representation in which a change to a single dimension in the first impacts all the dimensions of the second (they are entangled).", "There\u2019s no way for an unsupervised method to distinguish between these two equivalent generative models, and thus the resulting learned representation must be entangled with at least one of them.", "After observing  , we can construct many generative models which have the same marginal distribution of  .", "Any one of these models could be the true causal generative model for the data, and the right model cannot be identified given only the distribution of  .", "For a wonderful demonstration of this in lower dimensions, see \u2018 Same stats, different graphs \u2019.", "In practice, might we be able to learn disentangled representations anyway?", "While Theorem 1 shows that unsupervised disentanglement learning is fundamentally impossible for arbitrary generative models, this does not necessarily mean that it is an impossible endeavour in practice.", "After all, real world generative models may have a certain structure that could be exploited through suitably chosen inductive biases.", "But, the authors argue, you should make explicit the inductive biases you are selecting.", "To investigate all this the authors take six recent unsupervised disentanglement methods, train them over seven different data sets, and evaluate them using six different disentanglement measures.", "The result is  a corpus of more than 10,000 trained models.", "The library used to train and evaluate these models, disentanglement_lib has been made available at  [url]"], "author_id": "ACOLYER", "pdf_url": "http://proceedings.mlr.press/v97/locatello19a/locatello19a.pdf", "author_full_name": "Adrian Colyer", "source_website": "https://blog.acolyer.org/about/", "id": 84030160}