{"blog_id": "9dc0444142be8bd8a7404a226880eb", "summary": ["The paper proposes an adversarial approach for estimating generative models where one model (generative model) tries to learn a data distribution and another model (discriminative model) tries to distinguish between samples from the generative model and original data distribution.", "Adversarial Net  Two models - Generative Model(G) and Discriminative Model(D)  Both are multi-layer perceptrons.", "G takes as input a noise variable z and outputs data sample x(=G(z)).", "D takes as input a data sample x and predicts whether it came from true data or from G.  G tries to minimise log(1-D(G(z))) while D tries to maximise the probability of correct classification.", "Think of it as a minimax game between 2 players and the global optimum would be when G generates perfect samples and D can not distinguish between the samples (thereby always returning 0.5 as the probability of sample coming from true data).", "Alternate between k steps of training D and 1 step of training G so that D is maintained near its optimal solution.", "When starting training, the loss log(1-D(G(z))) would saturate as G would be weak.", "Instead maximise log(D(G(z)))  The paper contains the theoretical proof for global optimum of the minimax game.", "Experiments  Datasets  MNIST, Toronto Face Database, CIFAR-10  Generator model uses RELU and sigmoid activations.", "Discriminator model uses maxout and dropout.", "Evaluation Metric  Fit Gaussian Parzen window to samples obtained from G and compare log-likelihood.", "Strengths  Computational advantages  Backprop is sufficient for training with no need for Markov chains or performing inference.", "A variety of functions can be used in the model.", "Since G is trained only using the gradients from D, fewer chances of directly copying features from the true data.", "Can represent sharp (even degenerate) distributions.", "Weakness  D must be well synchronised with G.  While G may learn to sample data points that are indistinguishable from true data, no explicit representation can be obtained.", "Possible Extensions  Conditional generative models.", "Inference network to predict z given x.", "Implement a stochastic extension of the deterministic Multi-Prediction Deep Boltzmann Machines  Using discriminator net or inference net for feature selection.", "Accelerating training by ensuring better coordination between G and D or by determining better distributions to sample z from during training."], "author_id": "shugan", "pdf_url": "https://arxiv.org/pdf/1406.2661", "author_full_name": "Shagun Sodhani", "source_website": "https://github.com/shagunsodhani/papers-I-read", "id": 51450104}