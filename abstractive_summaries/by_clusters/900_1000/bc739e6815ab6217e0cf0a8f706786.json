{"blog_id": "bc739e6815ab6217e0cf0a8f706786", "summary": ["The paper introduces an architecture for end-to-end Reinforcement Learning (RL) optimization for task-oriented dialogue systems and its application to a multimodal task - grounding the dialogue into a visual context.", "Encoder Decoder Models vs RL Models  Encoder Decoder models do not account for the planning problems (which are inherent in the dialogue systems) and do not integrate seamlessly with external contexts or knowledge bases.", "RL models can handle the planning problem but require online learning and a predefined structure of the task.", "Dataset  Corpus of data collected for GuessWhat?!", "game  The goal of the game is to locate an unknown object in a rich image scene by asking a series of questions.", "The authors use their previous work in GuessWhat?!", "paper to build a supervised agent and a neural training environment.", "The agent and the environment are used to train a Deep RL agent online which can solve the task.", "Link to summary of GuessWhat?!", "paper  Training Environment  Oracle  Given an image and a question about the image, the oracle can reply in \"yes\" or \"no\" or \"not applicable\".", "Questioner  Given an image, and a list of previous question&answers (if applicable), the questioner generates a question with the aim of locating the object in the image.", "Guesser  Once the questioner is confident of having identified the image, the oracle presents a list of objects to the guesser to choose from.", "These components are based on the previous work by the authors where they develop nueral baselines for these components.", "GuessWhat!?", "as a Markov Decision Process  The state of the system is defined as the set of:  list of words/tokens generated so far in the current question  list of questions and answers so far  input image  The action space comprises of set of all the words in the vocabulary (5K in this context).", "Transition Graph  if <stop> word is choosen as the action, the full dialogue is terminated.", "if <?> word is choosen as the action, the current question is considered completed and the answer is sampled from the oracle.", "if any other word is chosen as the action, it is used to update the state of the systema and the process continues.", "Reward is defined for every state-action pair.", "The dialogue is automatically terminated after Jmax questions while the questions are automatically terminated after Imax words.", "The game can be modelled as an episodic RL scenario where generator can be trained using Policy Gradient methods.", "The paper defines the reward as 1 if the guesser could identify the correct object and 0 otherwise.", "Even though MDP assumption of \"reward being a function of state and action\" does not hold, policy gradient method employed by the paper (called as REINFORCE) is still applicable if the MDP is partially observable.", "Training Process  Train the oracle, the questioner and the guesser independently.", "Finetune the trained questioner using the proposed RL framework.", "Results  On test set, the baseline approach obtained 45% accuracy while the paper reports 53% accuracy.", "Beam search baseline (case of supervised encoder-decoder model) tends to repeat questions - an indication of poor generalization.", "Beam search basline also tends to generate longer sentences and incoherent sequence of questions (indicating towards the lack of planning component).", "RL trained model favours enumerating object categories and spatial information.", "RL trained model tends to generate shorter dialogues and uses a smaller set of vocabulary.", "One player, called as the oracle, is randomly assigned an object in the given image.", "The second player, called as the questioner, tries to locate the object, given just the image.", "The questioner can ask a series of questions about the object and the oracle can reply in \"yes\" or \"no\" or \"not applicable\".", "Once the questioner is confident of having identified the image, the oracle presents a list of objects to the questioner to choose from.", "A small penalty is added, every time a question is asked, so as to encourage informative questions only.", "GuessWhat?!", "Game  One player, called as the oracle, is randomly assigned an object in the given image.", "The second player, called as the questioner, tries to locate the object, given just the image.", "The questioner can ask a series of questions about the object and the oracle can reply in \"yes\" or \"no\" or \"not applicable\".", "Once the questioner is confident of having identified the image, the oracle presents a list of objects to the questioner to choose from.", "A small penalty is added, every time a question is asked, so as to encourage informative questions only.", "Dataset  A filtered subset of images from MSCOCO is used as the image set.", "Two separate tasks create on Amazon Mechanical Turk (AMT) - for the role of oracle and questioner.", "Data was post processed -- both manually and using AMT -- to account for things like spelling mistakes and validation.", "Final dataset comprises of 150K thousand human game iterations with 800K question-answer pairs on 60K images.", "Dataset is available at  [url]"], "author_id": "shugan", "pdf_url": "https://www.robots.ox.ac.uk/~vgg/publications/2014/Pickup14/pickup14.pdf", "author_full_name": "Shagun Sodhani", "source_website": "https://github.com/shagunsodhani/papers-I-read", "id": 89853012}